[
  {
    "objectID": "lesson-2.html",
    "href": "lesson-2.html",
    "title": "Actually using the model",
    "section": "",
    "text": "imgs = ddg_images(\"shar pei\", max_results=1)\n\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return ddg_images(term, max_results=max_images)\n\n\nbear_types = ['grizzly','black','teddy']\npath = Path('bears')\n\n\nfrom fastai.vision import utils as vutils\nfrom fastai.data.transforms import get_image_files\n\n\n\nIMG_LIMIT = 300\n\npath.mkdir(exist_ok=True)\nfor o in bear_types:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True)\n    fns = get_image_files(dest)\n    if len(fns) >= IMG_LIMIT:\n        continue\n    search_results = search_images(f'{o} bear', max_images=(IMG_LIMIT - len(fns)))\n    urls = [res[\"image\"] for res in search_results]\n    imgs = vutils.download_images(dest, urls=urls)\n\n\nfns = get_image_files(path)\n\n\nfrom fastai.vision import utils as vutils\nfailed = vutils.verify_images(fns)\nfailed\n\n(#0) []\n\n\n\nfailed.map(Path.unlink);\n\n\nfrom fastai.data import block, transforms\nfrom fastai.vision.data import ImageBlock\nfrom fastai.vision.learner import RandomSplitter, Resize\n\n\nbears = block.DataBlock(\n    blocks=(ImageBlock, block.CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=transforms.parent_label,\n    item_tfms=Resize(128))\n\n\ndls = bears.dataloaders(path)\n\n\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nfrom fastai.vision.learner import Resize, RandomResizedCrop\n\nbears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=4, nrows=1, unique=True)\n\n\n\n\n\nfrom fastai.vision.augment import aug_transforms\n\n# Data Augmentation\nbears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=True)\n\n\n\n\n\nbears = bears.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\ndls = bears.dataloaders(path)\n\n\nfrom fastai.vision.learner import vision_learner\nfrom fastai.vision.all import resnet18, error_rate\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n/home/matt/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/home/matt/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/matt/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.895106\n      0.099489\n      0.038889\n      00:18\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.151300\n      0.076215\n      0.033333\n      00:17\n    \n    \n      1\n      0.116786\n      0.063916\n      0.022222\n      00:16\n    \n    \n      2\n      0.092991\n      0.066528\n      0.022222\n      00:16\n    \n    \n      3\n      0.075252\n      0.071187\n      0.022222\n      00:16\n    \n  \n\n\n\n\nfrom fastai.interpret import ClassificationInterpretation\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1)\n\n\n\n\n\n\n\n\n\n\n\n\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Clearing out invalid data.\nfor idx in cleaner.delete():\n    cleaner.fns[idx].unlink()\n\n# For moving data from one folder to another\n# This assumes you're using the folder names as categories\nfor idx, category in cleaner.change():\n    shutil.move(str(cleaner.fns[idx]), path / category)\n\n\nlearn.export()\n\n\n# retrain\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=True)\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n/home/matt/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/home/matt/.pyenv/versions/3.9.13/envs/jupyter/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.940698\n      0.065609\n      0.022222\n      00:15\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.108798\n      0.063448\n      0.022222\n      00:17\n    \n    \n      1\n      0.101021\n      0.082268\n      0.016667\n      00:16\n    \n    \n      2\n      0.096700\n      0.042520\n      0.016667\n      00:16\n    \n    \n      3\n      0.078842\n      0.039166\n      0.016667\n      00:17\n    \n  \n\n\n\n\n\n\n\nlearn.export()\n\n\npath = Path()\npath.ls(file_exts='.pkl')\n\n(#1) [Path('export.pkl')]\n\n\n\nfrom fastai.learner import load_learner\nlearn_inf = load_learner(path/'export.pkl')\n\n\nlearn_inf.predict('bears/black/feb76760-e1aa-4f53-aa74-ab72354023ff.jpg')\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00<?]\n    \n    \n\n\nFileNotFoundError: [Errno 2] No such file or directory: 'bears/black/feb76760-e1aa-4f53-aa74-ab72354023ff.jpg'\n\n\n\nlearn_inf.predict('bears/grizzly/79b20ad1-2f7e-4c00-baa0-c34c70365e46.jpg')\n\n\nlearn_inf.dls.vocab"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "nbdev-pg",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "nbdev-pg",
    "section": "Install",
    "text": "Install\npip install nbdev_pg"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "nbdev-pg",
    "section": "How to use",
    "text": "How to use\nFill me in please! Donâ€™t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "lesson-2.bear-app.html",
    "href": "lesson-2.bear-app.html",
    "title": "nbdev-pg",
    "section": "",
    "text": "import numpy as np\nimport gradio as gr\n\ndef identify_image(img):\n    pred, pred_idx, probs = learn_inf.predict(img)\n    return f\"Looks like a {pred} bear\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Identify bears. Useful if you're currently being pursued by one.\")\n    with gr.Row():\n        image_input = gr.Image()\n    with gr.Row():\n        text_output = gr.Textbox(label=\"Identification\")\n    image_button = gr.Button(\"Identify\")\n    \n    image_button.click(identify_image, inputs=image_input, outputs=text_output)\n    \ndemo.launch(server_name='doomver.local')\n\nRunning on local URL:  http://doomver.local:7862\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\n(<gradio.routes.App at 0x7faba770d1c0>, 'http://doomver.local:7862/', None)\n\n\n\n?gr.Textbox"
  },
  {
    "objectID": "ssts-forecasting.html",
    "href": "ssts-forecasting.html",
    "title": "fastai method",
    "section": "",
    "text": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#from pathlib import Path\n\ndatap = Path('./kaggle/ssts-forecasting')\n\n\nfor dirname, _, filenames in os.walk(datap):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nkaggle/ssts-forecasting/train.csv\nkaggle/ssts-forecasting/test.csv\nkaggle/ssts-forecasting/oil.csv\nkaggle/ssts-forecasting/sample_submission.csv\nkaggle/ssts-forecasting/transactions.csv\nkaggle/ssts-forecasting/stores.csv\nkaggle/ssts-forecasting/holidays_events.csv\n\n\n\ntrain_data = pd.read_csv(datap / \"train.csv\")\ntrain_data.head()\ntrain_data.columns\n\nIndex(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion'], dtype='object')\n\n\n\ntest_data = pd.read_csv(datap / \"test.csv\")\ntest_data.head()\ntest_data.columns\n\nIndex(['id', 'date', 'store_nbr', 'family', 'onpromotion'], dtype='object')\n\n\n\ndef r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n\n\nprocs = [Categorify]\nfeatures = [\n    'id', 'date', 'store_nbr', 'family', 'onpromotion']\ndep_var = 'sales'\n# all_data = pd.concat([train_data, test_data], sort=False)\n# It looks to me like the test data has no survival column\nall_data = train_data[features + [dep_var]]\n\ncont, cat = cont_cat_split(all_data, 1, dep_var=dep_var)\n\nsplit_idx = int(math.floor(len(all_data) * 0.70))\nsplits = (list(range(0, split_idx)), \n          list(range(split_idx, len(all_data))))\n\n\nto = TabularPandas(\n    all_data[features + [dep_var]],\n    procs,\n    cat,\n    cont,\n    y_names=dep_var,\n    splits=splits\n)\nto.show(10)\n\n# save_pickle(datap / 'to.pkl', to)\n# to = (datap / 'to.pkl').load()\n\nxs,y = to.train.xs, to.train.y\nvalid_xs,valid_y = to.valid.xs, to.valid.y\n\n\n\n  \n    \n      \n      date\n      family\n      id\n      store_nbr\n      onpromotion\n      sales\n    \n  \n  \n    \n      0\n      2013-01-01\n      AUTOMOTIVE\n      0\n      1\n      0\n      0.0\n    \n    \n      1\n      2013-01-01\n      BABY CARE\n      1\n      1\n      0\n      0.0\n    \n    \n      2\n      2013-01-01\n      BEAUTY\n      2\n      1\n      0\n      0.0\n    \n    \n      3\n      2013-01-01\n      BEVERAGES\n      3\n      1\n      0\n      0.0\n    \n    \n      4\n      2013-01-01\n      BOOKS\n      4\n      1\n      0\n      0.0\n    \n    \n      5\n      2013-01-01\n      BREAD/BAKERY\n      5\n      1\n      0\n      0.0\n    \n    \n      6\n      2013-01-01\n      CELEBRATION\n      6\n      1\n      0\n      0.0\n    \n    \n      7\n      2013-01-01\n      CLEANING\n      7\n      1\n      0\n      0.0\n    \n    \n      8\n      2013-01-01\n      DAIRY\n      8\n      1\n      0\n      0.0\n    \n    \n      9\n      2013-01-01\n      DELI\n      9\n      1\n      0\n      0.0\n    \n  \n\n\n\n\nm = DecisionTreeRegressor(min_samples_leaf=10)\nm.fit(xs, y)\n\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n\n(269.138214, 547.068046)\n\n\n\ntest_to = TabularPandas(\n    test_data[features],\n    procs,\n    cat,\n    cont\n)\ntest_to.show(3)\ntest_cleaned = test_to.train.xs\n\n\n\n  \n    \n      \n      date\n      family\n      id\n      store_nbr\n      onpromotion\n    \n  \n  \n    \n      0\n      2017-08-16\n      AUTOMOTIVE\n      3000888\n      1\n      0\n    \n    \n      1\n      2017-08-16\n      BABY CARE\n      3000889\n      1\n      0\n    \n    \n      2\n      2017-08-16\n      BEAUTY\n      3000890\n      1\n      2\n    \n  \n\n\n\n\npredictions = m.predict(test_cleaned);\npredictions[0:10]\n\narray([   5.        ,    0.        ,    7.36842105, 2369.14285714,\n          0.        ,  380.13066228,   14.        ,  854.07142857,\n        854.07142857,  130.45626349])\n\n\n\noutput = pd.DataFrame(\n    {\n        'id': test_cleaned.id,\n        'sales': predictions,\n    }\n)\noutput\n\n\n\n\n\n  \n    \n      \n      id\n      sales\n    \n  \n  \n    \n      0\n      3000888\n      5.000000\n    \n    \n      1\n      3000889\n      0.000000\n    \n    \n      2\n      3000890\n      7.368421\n    \n    \n      3\n      3000891\n      2369.142857\n    \n    \n      4\n      3000892\n      0.000000\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      28507\n      3029395\n      408.866999\n    \n    \n      28508\n      3029396\n      82.983400\n    \n    \n      28509\n      3029397\n      1279.750586\n    \n    \n      28510\n      3029398\n      90.398313\n    \n    \n      28511\n      3029399\n      23.586200\n    \n  \n\n28512 rows Ã— 2 columns\n\n\n\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\nYour submission was successfully saved!"
  },
  {
    "objectID": "titanic.html",
    "href": "titanic.html",
    "title": "Kaggle method",
    "section": "",
    "text": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#from pathlib import Path\n\ndatap = Path('./kaggle/titanic')\n\nfor dirname, _, filenames in os.walk(datap):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nkaggle/titanic/train.csv\nkaggle/titanic/test.csv\nkaggle/titanic/gender_submission.csv\nkaggle/titanic/to.pkl\n\n\n\ntrain_data = pd.read_csv(datap / \"train.csv\")\ntrain_data.head()\ntrain_data.columns\n\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\n\n\ntest_data = pd.read_csv(datap / \"test.csv\")\ntest_data.head()\ntest_data.columns\n\nIndex(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n    \n  \n  \n    \n      0\n      892\n      0\n    \n    \n      1\n      893\n      1\n    \n    \n      2\n      894\n      0\n    \n    \n      3\n      895\n      0\n    \n    \n      4\n      896\n      1\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      413\n      1305\n      0\n    \n    \n      414\n      1306\n      1\n    \n    \n      415\n      1307\n      0\n    \n    \n      416\n      1308\n      0\n    \n    \n      417\n      1309\n      0\n    \n  \n\n418 rows Ã— 2 columns\n\n\n\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\nYour submission was successfully saved!\n\n\n\nfastai method\n\ndef r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n\n\nprocs = [FillMissing, Categorify, Normalize]\nfeatures = [\n    'Pclass', 'Sex',\n    'Age', 'SibSp', 'Parch', 'Cabin', \n    'Embarked', 'Fare', 'Ticket'\n]\ndep_var = 'Survived'\n# all_data = pd.concat([train_data, test_data], sort=False)\n# It looks to me like the test data has no survival column\nall_data = train_data[features + [dep_var]]\n\ncont, cat = cont_cat_split(all_data, 1, dep_var=dep_var)\n\nsplit_idx = int(math.floor(len(all_data) * 0.75))\nsplits = (list(range(0, split_idx)), \n          list(range(split_idx, len(all_data))))\n\n\nto = TabularPandas(\n    all_data[features + [dep_var]],\n    procs,\n    cat,\n    cont,\n    y_names=dep_var,\n    splits=splits\n)\nto.show(10)\n\n# save_pickle(datap / 'to.pkl', to)\n# to = (datap / 'to.pkl').load()\n\nxs,y = to.train.xs, to.train.y\nvalid_xs,valid_y = to.valid.xs, to.valid.y\n\n\n\n  \n    \n      \n      Sex\n      Cabin\n      Embarked\n      Ticket\n      Age_na\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n      Survived\n    \n  \n  \n    \n      0\n      male\n      #na#\n      S\n      A/5 21171\n      False\n      3.0\n      22.0\n      1.0\n      0.0\n      7.250000\n      0\n    \n    \n      1\n      female\n      C85\n      C\n      PC 17599\n      False\n      1.0\n      38.0\n      1.0\n      0.0\n      71.283302\n      1\n    \n    \n      2\n      female\n      #na#\n      S\n      STON/O2. 3101282\n      False\n      3.0\n      26.0\n      0.0\n      0.0\n      7.925000\n      1\n    \n    \n      3\n      female\n      C123\n      S\n      113803\n      False\n      1.0\n      35.0\n      1.0\n      0.0\n      53.099998\n      1\n    \n    \n      4\n      male\n      #na#\n      S\n      373450\n      False\n      3.0\n      35.0\n      0.0\n      0.0\n      8.050000\n      0\n    \n    \n      5\n      male\n      #na#\n      Q\n      330877\n      True\n      3.0\n      28.0\n      0.0\n      0.0\n      8.458300\n      0\n    \n    \n      6\n      male\n      E46\n      S\n      17463\n      False\n      1.0\n      54.0\n      0.0\n      0.0\n      51.862499\n      0\n    \n    \n      7\n      male\n      #na#\n      S\n      349909\n      False\n      3.0\n      2.0\n      3.0\n      1.0\n      21.075001\n      0\n    \n    \n      8\n      female\n      #na#\n      S\n      347742\n      False\n      3.0\n      27.0\n      0.0\n      2.0\n      11.133300\n      1\n    \n    \n      9\n      female\n      #na#\n      C\n      237736\n      False\n      2.0\n      14.0\n      1.0\n      0.0\n      30.070801\n      1\n    \n  \n\n\n\n\nm = DecisionTreeRegressor(min_samples_leaf=14)\nm.fit(xs, y)\n\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n\n(0.339971, 0.353539)\n\n\n\ntest_to = TabularPandas(\n    test_data[features],\n    procs,\n    cat,\n    cont\n)\ntest_to.show(3)\ntest_cleaned = test_to.train.xs\n\n\n\n  \n    \n      \n      Sex\n      Cabin\n      Embarked\n      Ticket\n      Age_na\n      Fare_na\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      0\n      male\n      #na#\n      Q\n      330911\n      False\n      False\n      3.0\n      34.5\n      0.0\n      0.0\n      7.8292\n    \n    \n      1\n      female\n      #na#\n      S\n      363272\n      False\n      False\n      3.0\n      47.0\n      1.0\n      0.0\n      7.0000\n    \n    \n      2\n      male\n      #na#\n      Q\n      240276\n      False\n      False\n      2.0\n      62.0\n      0.0\n      0.0\n      9.6875\n    \n  \n\n\n\n\ndel test_cleaned['Fare_na']\n\n\npredictions = m.predict(test_cleaned);\npredictions[0:10], predictions.round()[0:10]\n\n(array([0.        , 0.26666667, 0.38095238, 0.        , 0.65      ,\n        0.        , 0.57142857, 0.38095238, 0.57142857, 0.        ]),\n array([0., 0., 0., 0., 1., 0., 1., 0., 1., 0.]))\n\n\n\noutput = pd.DataFrame(\n    {\n        'PassengerId': test_data.PassengerId,\n        'Survived': predictions.round().astype(int)\n    }\n)\noutput\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n    \n  \n  \n    \n      0\n      892\n      0\n    \n    \n      1\n      893\n      0\n    \n    \n      2\n      894\n      0\n    \n    \n      3\n      895\n      0\n    \n    \n      4\n      896\n      1\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      413\n      1305\n      0\n    \n    \n      414\n      1306\n      1\n    \n    \n      415\n      1307\n      0\n    \n    \n      416\n      1308\n      0\n    \n    \n      417\n      1309\n      0\n    \n  \n\n418 rows Ã— 2 columns\n\n\n\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\nYour submission was successfully saved!"
  },
  {
    "objectID": "Gradio.html",
    "href": "Gradio.html",
    "title": "nbdev-pg",
    "section": "",
    "text": "import numpy as np\nimport gradio as gr\n\ndef sepia(input_img):\n    sepia_filter = np.array([\n        [0.393, 0.769, 0.189], \n        [0.349, 0.686, 0.168], \n        [0.272, 0.534, 0.131]\n    ])\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ndemo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\ndemo.launch()\n\nRunning on local URL:  http://127.0.0.1:7862/\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\n(<gradio.routes.App at 0x7fa3ca976230>, 'http://127.0.0.1:7862/', None)\n\n\n\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    greet_btn.click(fn=greet, inputs=name, outputs=output)\n\ndemo.launch()\n\nRunning on local URL:  http://127.0.0.1:7862/\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\n(<gradio.routes.App at 0x7f8562bfdab0>, 'http://127.0.0.1:7862/', None)\n\n\n\nimport numpy as np\nimport gradio as gr\n\ndef flip_text(x):\n    return x[::-1]\n\ndef flip_image(x):\n    return np.fliplr(x)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tabs():\n        with gr.TabItem(\"Flip Text\"):\n            text_input = gr.Textbox()\n            text_output = gr.Textbox()\n            text_button = gr.Button(\"Flip\")\n        with gr.TabItem(\"Flip Image\"):\n            with gr.Row():\n                image_input = gr.Image()\n                image_output = gr.Image()\n            image_button = gr.Button(\"Flip\")\n    \n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n    \ndemo.launch()\n\nRunning on local URL:  http://127.0.0.1:7860/\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\n(<gradio.routes.App at 0x7f179e955510>, 'http://127.0.0.1:7860/', None)"
  },
  {
    "objectID": "lesson-4.graphing.html",
    "href": "lesson-4.graphing.html",
    "title": "nbdev-pg",
    "section": "",
    "text": "import math\n\ndef mse(pred,y):\n    return ((pred-y)**2).mean()\n\ndef rmse(pred,y):\n    return round(math.sqrt(mse(pred, y), 6))\n\ndef quad_mse(params):\n    f = mk_quad(*params)\n    return mse(f(x), y)\n\ndef quad_rmse(params):\n    f = mk_quad(*params)\n    return rmse(f(x), y)\n\n\nf = mk_quad(3, 2, 1)\nx = torch.linspace(-2, 2, steps=20)[:,None]\ny = add_noise(f(x), 0.3, 1.5)\n\n@interact(a=1.5, b=1.5, c=1.5)\ndef plot_quad(a, b, c):\n    f_guess = mk_quad(a, b, c)\n    mse_loss = mse(f_guess(x), y)\n    rmse_loss = r_mse(f_guess(x), y)\n\n    ax = plot_function(\n        f_guess,\n        min=-3,\n        max=3,\n        title=f\"MSE: {mse_loss:.2f}, RMSE: {rmse_loss:.2f}\"\n    )\n    ax.scatter(x, y)\n\n\n\n\n\nabc = torch.tensor([1.5, 1.5, 1.5], requires_grad=True)\nloss = quad_mse(abc)\nloss.backward()\n\n# grad represents the direction you should go.\n# positions correspond to parameters\n# negative values means you should increase the parameter\n# higher absolute values indicate greater relative importance\nabc.grad\n\ntensor([-8.8910, -4.1143, -2.8729])\n\n\n\n# basically every machine learning model does this repeatedly\n# This is gradient descent, bitches\nwith torch.no_grad():\n    abc -= abc.grad * 0.01\n    loss = quad_mse(abc)\n\nprint(f'loss={loss:.2f}; abc={abc}')\n\nloss=6.55; abc=tensor([2.7447, 2.0760, 1.9022], requires_grad=True)\n\n\n\n# Ok, so this works fine for quadratic equations.\n# How do we make this work for much more complicated\n# things like image identification?\n\ndef rectified_linear(m, b, x):\n    y = m*x + b\n    # clip will force all negative values to match the 2nd param (0.0)\n    return torch.clip(y, 0.0)\n\ndef dub_rectified_linear(m1, b1, m2, b2, x):\n    return rectified_linear(m1, b1, x) + rectified_linear(m2, b2, x)\n\n# essentially, just keep adding linear functions\n# together to represent arbitrarily complex functions.\n\n\n@interact(m=1.5, b=1.5)\ndef plot_rect_lin(m, b):\n    func = partial(rectified_linear, m, b)\n    ax = plot_function(\n        func,\n        min=-3,\n        max=3,\n    )\n\n\n\n\n\n@interact(m1=-1.5, b1=-1.5, m2=1.5, b2=1.5)\ndef plot_double_rect_lin(m1, b1, m2, b2):\n    func = partial(dub_rectified_linear, m1, b1, m2, b2)\n    ax = plot_function(\n        func,\n        min=-3,\n        max=3,\n    )"
  },
  {
    "objectID": "lesson-4.html",
    "href": "lesson-4.html",
    "title": "nbdev-pg",
    "section": "",
    "text": "path = untar_data(URLs.MNIST_SAMPLE)\n\n\n\n\n\n\n    \n      \n      100.14% [3219456/3214948 00:00<00:00]\n    \n    \n\n\n\n#hide\nPath.BASE_PATH = path\n\n\npath.ls()\n\n(#3) [Path('labels.csv'),Path('train'),Path('valid')]\n\n\n\n(path/'train').ls()\n\n(#2) [Path('train/3'),Path('train/7')]\n\n\n\nthrees = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\nthrees\n\n(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]\n\n\n\nim3_path = threes[1]\nim3 = Image.open(im3_path)\nim3\n\n\n\n\n\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nlen(three_tensors),len(seven_tensors)\n\n(6131, 6265)\n\n\n\nshow_image(three_tensors[1]);\n\n\n\n\n\nstacked_sevens = torch.stack(seven_tensors).float()/255\nstacked_threes = torch.stack(three_tensors).float()/255\nstacked_threes.shape\n\ntorch.Size([6131, 28, 28])\n\n\n\nstacked_threes.ndim\n\n3\n\n\n\nstacked_threes.ndim == len(stacked_threes.shape)\n\nTrue\n\n\n\nmean3 = stacked_threes.mean(0)\nshow_image(mean3)\n\n\n\n\n\nmean7 = stacked_sevens.mean(0)\nshow_image(mean7)\n\n<AxesSubplot:>\n\n\n\n\n\n\na_3 = stacked_threes[1]\nshow_image(a_3);\n\n\n\n\nHow do we determine the error with the averages?\n\nTake the mean of the absolute value of differences (absolute value is the function that replaces negative values with positive values).\n\nCalled the mean absolute difference or L1 norm\nPenalizes big mistakes less\nPenalizes small mistakes more\n\nTake the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring).\n\nCalled the root mean squared error (RMSE) or L2 norm\nPenalizes big mistakes more\nPenalizes small mistakes less\n\n\n\ndist_3_abs = (a_3 - mean3).abs().mean()\ndist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\ndist_3_abs,dist_3_sqr\n\n(tensor(0.1114), tensor(0.2021))\n\n\n\ndist_7_abs = (a_3 - mean7).abs().mean()\ndist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\ndist_7_abs,dist_7_sqr\n\n(tensor(0.1586), tensor(0.3021))\n\n\n\n# The calculations above are provided by pytorch\nimport torch.nn.functional as F\nF.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()\n\n(tensor(0.1586), tensor(0.3021))\n\n\n\ndata = [[1,2,3],[4,5,6]]\ntns = tensor(data)\ntns\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntns[1]\n\ntensor([4, 5, 6])\n\n\n\n# select a column\ntns[:,1]\n\ntensor([2, 5])\n\n\n\n# select part of a row\ntns[1,1:3]\n\ntensor([5, 6])\n\n\n\ntns+1\n\ntensor([[2, 3, 4],\n        [5, 6, 7]])\n\n\n\ntns.type()\n\n'torch.LongTensor'\n\n\n\ntns * 1.5\n\ntensor([[1.5000, 3.0000, 4.5000],\n        [6.0000, 7.5000, 9.0000]])\n\n\n\n(tns * 1.5).type()\n\n'torch.FloatTensor'"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "lesson-1.html",
    "href": "lesson-1.html",
    "title": "nbdev-pg",
    "section": "",
    "text": "#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n#    If you get a JSON error, just try running it again (it may take a couple of tries).\nurls = search_images('bird photos', max_images=1)\nurls[0]\n\nSearching for 'bird photos'\n\n\n'https://amazinganimalphotos.com/wp-content/uploads/2016/11/beautiful-birds.jpeg'\n\n\n\nfrom fastdownload import download_url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\ndownload_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\n\nsearches = 'forest','bird'\npath = Path('bird_or_not')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0\n\n\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/home/matt/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/home/matt/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/matt/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.864567\n      1.536042\n      0.235294\n      00:02\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.312403\n      0.425286\n      0.147059\n      00:01\n    \n    \n      1\n      0.171983\n      0.211438\n      0.029412\n      00:01\n    \n    \n      2\n      0.114812\n      0.117522\n      0.029412\n      00:01\n    \n  \n\n\n\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a birad: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 1.0000"
  }
]